{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2, imageio\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, \\\n",
    "Conv2D, Flatten, TimeDistributed, LSTM\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_imagenet_model(pretrained_model):\n",
    "\n",
    "    base_model_out = pretrained_model.output\n",
    "\n",
    "    base_model_out = Flatten()(base_model_out)\n",
    "\n",
    "    # Add 3 dense layers so that the model can learn aspects of our new dataset\n",
    "    base_model_out = Dense(1024, activation='relu')(base_model_out)\n",
    "    base_model_out = Dropout(0.5)(base_model_out)\n",
    "    base_model_out = BatchNormalization()(base_model_out)\n",
    "    \n",
    "    base_model_out = Dense(512, activation='relu')(base_model_out)\n",
    "    base_model_out = Dropout(0.25)(base_model_out)\n",
    "    base_model_out = BatchNormalization()(base_model_out)\n",
    "\n",
    "    # Add a final layer with 3 neurons, one for each class in our dataset \n",
    "    # using a softmabase_model_out activation function:\n",
    "    preds = Dense(1, activation='sigmoid')(base_model_out)\n",
    "\n",
    "    # Instantiate our final model, where we specify what are the inputs and \n",
    "    # the outputs will look like\n",
    "    model = Model(inputs = pretrained_model.input, outputs = preds)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://mc.ai/train-keras-model-with-large-dataset-batch-training/\n",
    "def load_data(df, batch_n, batch_size, subset):\n",
    "    if batch_n > 0:\n",
    "        df = pd.read_csv(df, skiprows=batch_n*batch_size+1, nrows=batch_size, names=['filename', 'label'])\n",
    "    else:\n",
    "        df = pd.read_csv(df, skiprows=batch_n*batch_size, nrows=batch_size)\n",
    "    \n",
    "    frames = []\n",
    "    for dir in df['filename']:\n",
    "        try:\n",
    "            frame_path = subset + '/' + dir + '/' + os.listdir(subset + '/' + dir)[14]\n",
    "        #if 15th frame does not exist, use first frame\n",
    "        except IndexError:\n",
    "            frame_path = subset + '/' + dir + '/' + os.listdir(subset + '/' + dir)[0]\n",
    "\n",
    "        frame = imageio.imread(frame_path)\n",
    "\n",
    "        frames.append(frame)\n",
    "    \n",
    "    frames = np.array(frames)\n",
    "    x = frames.astype('float32')\n",
    "    x /= 255\n",
    "    \n",
    "    y = np.array(df['label'])\n",
    "    \n",
    "    #print(f'{batch_n} passed')\n",
    "    return (x, y)\n",
    "\n",
    "def batch_generator(df, batch_size, steps, subset):\n",
    "    batch_n=1\n",
    "    while True: \n",
    "        yield load_data(df, batch_n-1, batch_size, subset)\n",
    "    if batch_n < steps:\n",
    "        batch_n+=1\n",
    "    else:\n",
    "        batch_n=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline CNN Performance using 1 frame per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(160, 160, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_imagenet_model(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:len(vgg.layers)]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "opt = Adam(lr=0.001, decay = 0.0001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "TOTAL_FILES = metadata_train.shape[0]\n",
    "\n",
    "steps_per_epoch = np.ceil(TOTAL_FILES/BATCH_SIZE)\n",
    "train_generator = batch_generator('train.csv', BATCH_SIZE, steps_per_epoch, subset='train')\n",
    "validation_generator = batch_generator('validation.csv', BATCH_SIZE, steps_per_epoch, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "699/699 [==============================] - 138s 197ms/step - loss: 0.0943 - acc: 0.9624 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "699/699 [==============================] - 134s 191ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 8.2778e-04 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "699/699 [==============================] - 134s 191ms/step - loss: 5.2082e-04 - acc: 1.0000 - val_loss: 2.8932e-04 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "211/699 [========>.....................] - ETA: 52s - loss: 3.0572e-04 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2e438b86eb2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit_generator(train_generator, epochs=EPOCHS, steps_per_epoch=steps_per_epoch, \\\n\u001b[1;32m----> 2\u001b[1;33m                     verbose=1, shuffle=True, validation_data=validation_generator, validation_steps=steps_per_epoch)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\neuralnetworks\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1759\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1760\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1761\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1763\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\neuralnetworks\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         outs = model.train_on_batch(\n\u001b[1;32m--> 190\u001b[1;33m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\neuralnetworks\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\neuralnetworks\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2895\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m     \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\neuralnetworks\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=EPOCHS, steps_per_epoch=steps_per_epoch, \\\n",
    "                    verbose=1, shuffle=True, validation_data=validation_generator, validation_steps=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5585"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_train = pd.read_csv('metadata_train.csv')\n",
    "metadata_train['filename'] = metadata_train['filename'].str.replace('data_30/', '')\n",
    "\n",
    "# export csv with clean filenames for batch generation\n",
    "metadata_train.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_validation = pd.read_csv('metadata_validation.csv')\n",
    "metadata_validation['filename'] = metadata_validation['filename'].str.replace('train/', '')\n",
    "\n",
    "metadata_validation.to_csv('validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = metadata_train.sample(n=192, random_state=1)\n",
    "test_files.to_csv('test_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = metadata_validation.sample(n=128, random_state=1)\n",
    "val_files.to_csv('validation_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yidrboessk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ammowfdpae</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cytdctacrw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>huhzyknoqo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yfzulfwjue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>geglgdrsgp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>hsvbimzuza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>yxdleubquk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>xhwnzeozrd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>wzsfoifswy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename  label\n",
       "0    yidrboessk      1\n",
       "1    ammowfdpae      1\n",
       "2    cytdctacrw      1\n",
       "3    huhzyknoqo      1\n",
       "4    yfzulfwjue      1\n",
       "..          ...    ...\n",
       "123  geglgdrsgp      1\n",
       "124  hsvbimzuza      1\n",
       "125  yxdleubquk      1\n",
       "126  xhwnzeozrd      1\n",
       "127  wzsfoifswy      1\n",
       "\n",
       "[128 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('validation_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "TOTAL_FILES = 64\n",
    "\n",
    "steps_per_epoch = np.ceil(TOTAL_FILES/BATCH_SIZE)\n",
    "my_batch_generator = batch_generator('test_file.csv', BATCH_SIZE, steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batch_generator = batch_generator('val_file.csv', BATCH_SIZE, steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 3s 430ms/step - loss: 0.7035 - acc: 0.6875\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.6903 - acc: 0.7500: 0s - loss: 0.6909 - acc: 0\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.6884 - acc: 0.7500\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.6865 - acc: 0.7500\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.6846 - acc: 0.7500\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.6827 - acc: 0.7500\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.6808 - acc: 0.7500\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.6790 - acc: 0.7500\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.6772 - acc: 0.7500\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.6753 - acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1406574fd68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit_generator(my_batch_generator, epochs=EPOCHS, steps_per_epoch=steps_per_epoch, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = my_model.predict_generator(val_batch_generator, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5158261],\n",
       "       [0.5195586],\n",
       "       [0.5195586],\n",
       "       [0.5195586],\n",
       "       [0.5195586],\n",
       "       [0.5195586],\n",
       "       [0.5195586],\n",
       "       [0.5195586]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = prediction.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_out = vgg.output\n",
    "\n",
    "base_model_out = Flatten()(base_model_out)\n",
    "\n",
    "# Add 3 dense layers so that the model can learn aspects of our new dataset \n",
    "# and classify for better results.\n",
    "base_model_out = Dense(4, activation='relu')(base_model_out)\n",
    "\n",
    "# Add a final layer with 3 neurons, one for each class in our dataset \n",
    "# using a softmabase_model_out activation function:\n",
    "preds = Dense(2, activation='softmax')(base_model_out)\n",
    "\n",
    "# Instantiate our final model, where we specify what are the inputs and \n",
    "# the outputs will look like\n",
    "model = Model(inputs = vgg.input, outputs = preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = 'Adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16019374111304201060\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1431348428\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4326638991357481936\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "0 passed\n",
      "0 passed\n",
      "0 passed\n",
      "0 passed\n",
      "0 passed\n",
      "0 passed\n",
      "0 passed\n",
      "0 passed\n",
      "0 passed\n",
      "0 passed\n",
      "0 passed\n",
      "1/3 [=========>....................] - ETA: 43s - loss: 0.5519 - acc: 0.85000 passed\n",
      "2/3 [===================>..........] - ETA: 18s - loss: 1.2083 - acc: 0.85000 passed\n",
      "3/3 [==============================] - 50s 17s/step - loss: 0.9921 - acc: 0.8500\n",
      "Epoch 2/2\n",
      "0 passed\n",
      "1/3 [=========>....................] - ETA: 28s - loss: 0.4908 - acc: 0.85000 passed\n",
      "2/3 [===================>..........] - ETA: 13s - loss: 0.4694 - acc: 0.85000 passed\n",
      "3/3 [==============================] - 43s 14s/step - loss: 0.4562 - acc: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bde4219400>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(my_batch_generator, epochs=EPOCHS, steps_per_epoch=steps_per_epoch, verbose=1) #shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss: 0.6924 - acc: 0.6000\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.6923 - acc: 0.6000\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.6921 - acc: 0.6000\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.6920 - acc: 0.6000\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.6918 - acc: 0.6000\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.6916 - acc: 0.6000\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.6915 - acc: 0.6000\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.6913 - acc: 0.6000\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.6912 - acc: 0.6000\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.6910 - acc: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1882a873f28>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = frames\n",
    "y = np.array([1, 1, 0, 0, 1])\n",
    "\n",
    "model.fit(X, y, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for dir in os.listdir('test_dir'):\n",
    "    names.append(dir)\n",
    "\n",
    "test_metadata = pd.DataFrame({'names':names, 'labels':[1,1,0,0,1]})\n",
    "\n",
    "test_metadata.to_csv('test_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = load_data('test_metadata.csv', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "steps_per_epoch=np.ceil(5/batch_size)\n",
    "my_training_batch_generator = batch_generator('test_metadata.csv', batch_size, steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 434ms/step - loss: 0.6476 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 421ms/step - loss: 0.6443 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 442ms/step - loss: 0.6411 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 467ms/step - loss: 0.6379 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 455ms/step - loss: 0.6348 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 420ms/step - loss: 0.6317 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 419ms/step - loss: 0.6286 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 418ms/step - loss: 0.6255 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 419ms/step - loss: 0.6225 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 418ms/step - loss: 0.6195 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1882fa566d8>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(my_training_batch_generator, epochs=10, steps_per_epoch=steps_per_epoch,\n",
    "                    shuffle=True, verbose=1) # use_multiprocessing=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-20a5c97826ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\neuralnetworks\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1476\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1477\u001b[0m       return training_arrays.predict_loop(\n\u001b[1;32m-> 1478\u001b[1;33m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1480\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\neuralnetworks\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, inputs, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;31m# Sample-based predictions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m     \u001b[0mbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m     \u001b[0mindex_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_end\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\neuralnetworks\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mmake_batches\u001b[1;34m(size, batch_size)\u001b[0m\n\u001b[0;32m    465\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0mof\u001b[0m \u001b[0marray\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m   \"\"\"\n\u001b[1;32m--> 467\u001b[1;33m   \u001b[0mnum_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m   return [(i * batch_size, min(size, (i + 1) * batch_size))\n\u001b[0;32m    469\u001b[0m           for i in range(0, num_batches)]\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "model.predict(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114 images belonging to 5 classes.\n",
      "Found 26 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255, validation_split=0.2)\n",
    "\n",
    "training_set = datagen.flow_from_directory('test_dir', target_size = (160, 160), shuffle=True,\n",
    "                                             seed=2020, batch_size = 2, class_mode = 'binary',\n",
    "                                             subset=\"training\")\n",
    "\n",
    "val_set = datagen.flow_from_directory('test_dir', target_size = (160, 160), shuffle=True,\n",
    "                                             seed=2020, batch_size = 2, class_mode = 'binary',\n",
    "                                             subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D convolution will merge frames together, which may not be desirable.\n",
    "# https://medium.com/smileinnovation/how-to-work-with-time-distributed-data-in-a-neural-network-b8b39aa4ce00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "resnet = ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(160, 160, 3)\n",
    ")\n",
    "\n",
    "for layer in resnet.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'as_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-cc2ec0e27bdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model.add(\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mTimeDistributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m160\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m160\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\neuralnetworks\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    161\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\neuralnetworks\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\neuralnetworks\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0muses_learning_phase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m       \u001b[1;31m# Shape: (num_samples, timesteps, ...)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m       \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m       \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\neuralnetworks\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    177\u001b[0m                                                  input_shape[2:])\n\u001b[0;32m    178\u001b[0m     child_output_shape = self.layer.compute_output_shape(\n\u001b[1;32m--> 179\u001b[1;33m         child_input_shape).as_list()\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[0mtimesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     return tensor_shape.TensorShape([child_output_shape[0], timesteps] +\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'as_list'"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    TimeDistributed(vgg)()\n",
    ")\n",
    "\n",
    "model.add(\n",
    "    TimeDistributed(\n",
    "        Flatten()\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(LSTM(256, activation='relu', return_sequences=False))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = 'Adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.wrappers.TimeDistributed at 0x188000634a8>,\n",
       " <tensorflow.python.keras.layers.wrappers.TimeDistributed at 0x18800063160>,\n",
       " <tensorflow.python.keras.layers.recurrent.LSTM at 0x18800063208>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x18800063128>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x18800063710>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x18800063898>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = a\n",
    "y_train = np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2/2 [==============================] - 14s 7s/step - loss: 0.6726 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 9s 5s/step - loss: 1.1921e-07 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2777329cdd8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_frame = imageio.imread(\"data_30/aakkdgsmvl/000.png\")\n",
    "sample_frame2 = imageio.imread(\"data_30/aassnaulhq/000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 160, 160, 3)\n",
      "(2, 160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([sample_frame, sample_frame2])\n",
    "\n",
    "img_rows, img_cols = 160, 160\n",
    "\n",
    "# scale pixel values to be between 0 and 1\n",
    "a_scaled = a.astype('float32')\n",
    "a_scaled /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 160, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(shape=(160,160,3))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
      "91889664/91884032 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = Xception(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x2770b689358>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2770b689978>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770b689940>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770b689898>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2770b78ed30>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770b7baba8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770b6fc9b0>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770b7fdf60>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770b8a9240>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770b8bceb8>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770b97cfd0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770b9afda0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2770b7e4c88>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2770b941a20>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770b8616a0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x2770ba575c0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770bad7fd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770bb025c0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770bb366a0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770bb148d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770bbd0978>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770bc57978>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2770ba57da0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2770bbbe6d8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770bad7b00>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x2770bc9a630>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770bd4ffd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770bd7e9e8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770bdede80>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770bd89ba8>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770be51470>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770becc5c0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2770bc9a6d8>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2770be6a1d0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770bcd5860>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x27775cd0e80>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x277749dbf98>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770b60f2e8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770b69f048>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770bfbcd30>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770bfbcda0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770c0676d8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770c00b240>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770c0ae1d0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770c0f6cf8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x2770c0cc470>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770afd4ba8>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770c184400>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770c1c1470>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770c1c1358>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770c264198>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770c2acc50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770c29f2e8>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770d324dd8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770d35a940>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x2770d34a2b0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770c198eb8>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770d3edef0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770d3ccda0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770d4264e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770d4ab860>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770d51f9b0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770d507d30>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770d5a5be0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770d5fbf60>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x2770d587b00>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770d402978>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770d680c18>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770d6a0438>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770d6dcfd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770d74df28>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770d77ef60>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770d77eb38>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770d83cba8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770d858c18>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x2770d877278>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770d6678d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770d9199e8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770d9b7cc0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770d9076a0>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770da14be0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770da32f28>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770d9e4358>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770dad3940>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770db74c18>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x2770db2f6d8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770d93cc88>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770dbb0390>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770dc57048>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770dbdad68>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770dcb7ba8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770db0fa20>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770dc82b38>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770dd70f98>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770dd9f908>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x2770dd93cf8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770dbb0a90>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770deccda0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770de6c9b0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770de6cd68>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770df2a630>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770dfaa6a0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770df4ebe0>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770dff83c8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770e08b588>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x2770e028208>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770de3f7f0>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770e11cb38>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770e111748>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770e111b00>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770e1c8da0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770e2445c0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770e1e30b8>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770e2a4e80>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770e2d8a90>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x2770e2cb3c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770e3a8240>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770e449e48>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770e468240>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770e428e10>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770e5162e8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770e5a8550>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2770e36cef0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2770e546198>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770e3bd4a8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x2770e606da0>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770e669e48>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770e6a7c88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770e62e0f0>,\n",
       " <tensorflow.python.keras.layers.convolutional.SeparableConv2D at 0x2770e6d3e80>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x2770e789be0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2770e7046d8>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x2770e7e6240>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2770e7e6da0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'predictions/Softmax:0' shape=(?, 1000) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-1].output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
